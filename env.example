# Sampler Benchmark Environment Configuration
# Copy this to .env and fill in your actual API keys

# ============================================================================
# OPENROUTER CONFIGURATION (for LLM Judges)
# ============================================================================

# OpenRouter API Key (get from https://openrouter.ai/keys)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Multiple Judge Models (comma-separated for multi-judge evaluation)
# Available high-quality models on OpenRouter:
LLM_JUDGE_MODELS=openai/gpt-4-turbo,anthropic/claude-3.5-sonnet,google/gemini-pro-1.5

# Primary judge model (fallback for single-judge mode)
LLM_JUDGE_MODEL=openai/gpt-4-turbo

# Legacy API key field (will be replaced by OPENROUTER_API_KEY)
LLM_JUDGE_API_KEY=your_openrouter_api_key_here

# ============================================================================
# JUDGE CONFIGURATION
# ============================================================================

# Judge evaluation settings
LLM_JUDGE_BATCH_SIZE=5
LLM_JUDGE_TIMEOUT=60
LLM_JUDGE_TEMPERATURE=0.2
LLM_JUDGE_MAX_TOKENS=1500

# Multi-judge settings
MULTI_JUDGE_ENABLED=true
JUDGE_CONSENSUS_METHOD=average  # Options: average, weighted_average, majority_vote
JUDGE_DIVERSITY_BONUS=0.1      # Bonus for high inter-judge agreement

# ============================================================================
# GENERATION MODEL CONFIGURATION
# ============================================================================

# Local model server (KoboldCpp)
MODEL_SERVER_HOST=localhost
MODEL_SERVER_PORT=5001
MODEL_SERVER_TIMEOUT=300

# Model paths (adjust to your setup)
MODELS_DIR=/home/franc/llms/

# ============================================================================
# EXPERIMENTAL CONFIGURATION
# ============================================================================

# Output and caching
RESULTS_DIR=results
CACHE_ENABLED=true
CACHE_DIR=cache

# Performance settings
MAX_CONCURRENT_GENERATIONS=1
MAX_CONCURRENT_EVALUATIONS=5

# Debugging
DEBUG_MODE=false
VERBOSE_LOGGING=false